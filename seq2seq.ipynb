{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-As_031gem5N"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QJAU7xhVgTrX"
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scdaLyaBfNl7",
    "outputId": "fa2be2c1-e054-464b-b8a8-3b0f36256c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 1.33MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 232kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 223kB/s]\n"
     ]
    }
   ],
   "source": [
    "spacy_ger = spacy.load(\"de\")\n",
    "spacy_eng = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "def tokenize_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "\n",
    "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".de\", \".en\"), fields=(german, english)\n",
    ")\n",
    "\n",
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OG3CC3IYgi-Q"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True)\n",
    "\n",
    "    def forward(self, x): \n",
    "        embedding = self.dropout(self.embedding(x))  \n",
    "        outputs, (hidden, cell) = self.rnn(embedding) \n",
    "        \n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    # In decoder we are passing word by word\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):  \n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):  \n",
    "        x = x.unsqueeze(1)  \n",
    "        embedding = self.dropout(self.embedding(x)) \n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell)) \n",
    "        predictions = self.fc(outputs)  \n",
    "        predictions = predictions.squeeze(1)  \n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5): \n",
    "        batch_size = source.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[:, 0]  # shape is (N)\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)  \n",
    "\n",
    "            x = target[:, t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8iO1eIqkhm3U"
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "load_model = False\n",
    "input_size_encoder = len(german.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024  \n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LwqdOqa1Nl5L"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    spacy_ger = spacy.load(\"de\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]  \n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]  \n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(0).to(device)  \n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(sentence_tensor)  \n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(previous_word, hidden, cell)  \n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M53I0riceKCM",
    "outputId": "d37cc74a-a662-4062-86c1-981987cdaa29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'follow', 'follow', 'follow', 'tips', 'tips', 'pork', 'bronco', 'bronco', 'cans', 'cook', 'contains', 'cook', 'approximately', 'garden', 'garden', 'row', 'row', 'row', 'canvas', 'canvas', 'swamp', 'swamp', 'mets', 'stories', 'reason', 'reason', 'kissing', 'reception', 'players', 'flutes', 'scarf', 'sat', 'sat', 'drifts', 'armor', 'posed', 'steel', 'bows', 'tips', 'wild', 'making', 'making', 'reception', 'pork', 'pork', 'removes', 'contains', 'reception', 'seattle', 'bring']\n",
      "[Epoch 1 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'black', 'player', 'is', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 2 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'football', 'player', 'with', 'a', '<unk>', '<unk>', '<unk>', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 3 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', '<unk>', 'with', 'a', '<unk>', 'of', 'a', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 4 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'runner', 'with', 'with', 'a', 'number', '<unk>', 'is', 'being', 'being', 'by', 'a', '<unk>', '.', '<eos>']\n",
      "[Epoch 5 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'man', 'with', 'many', 'number', 'pulled', 'is', 'being', 'pulled', 'by', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 6 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'of', 'a', 'in', 'a', 'race', 'being', 'being', 'by', 'a', 'from', 'a', '.', '.', '<eos>']\n",
      "[Epoch 7 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'with', 'number', 'pulled', 'by', 'a', 'large', ',', 'by', 'a', 'large', '.', '.', '<eos>']\n",
      "[Epoch 8 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'boat', 'with', 'large', 'pulled', 'pulled', 'by', 'by', 'a', 'large', 'large', '.', '<eos>']\n",
      "[Epoch 9 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'boat', 'with', 'large', 'pulled', 'pulled', 'by', 'a', 'large', 'large', 'of', 'a', '.', '<eos>']\n",
      "[Epoch 10 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'many', 'pulled', 'pulled', 'by', 'by', 'a', 'large', 'by', 'a', 'large', '.', '.', '<eos>']\n",
      "[Epoch 11 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'many', 'cowboy', 'pulled', 'pulled', 'by', 'a', 'large', 'large', 'a', 'large', '.', '<eos>']\n",
      "[Epoch 12 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'car', 'with', 'many', 'pulled', 'pulled', 'pulled', 'by', 'a', 'large', '<unk>', 'of', '.', '<eos>']\n",
      "[Epoch 13 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'cowboy', 'many', 'pulled', 'pulled', 'pulled', 'by', 'a', 'large', 'bull', 'by', 'a', 'large', 'crowd', '.', '<eos>']\n",
      "[Epoch 14 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'boat', 'with', 'many', 'passengers', 'pulled', 'by', 'a', 'large', 'large', 'large', 'river', '.', 'horses', '.', '<eos>']\n",
      "[Epoch 15 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'many', 'men', 'pulled', 'pulled', 'by', 'a', 'large', ',', 'a', 'large', 'bull', '.', 'horses', '.', '<eos>']\n",
      "[Epoch 16 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'many', 'men', 'pulled', 'pulled', 'by', 'a', 'large', 'bull', 'by', 'a', 'large', 'bull', '.', '<eos>']\n",
      "[Epoch 17 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'many', 'men', 'pulled', 'by', 'a', 'large', 'bull', 'by', 'a', 'large', 'wave', '.', '<eos>']\n",
      "[Epoch 18 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'sunset', 'with', 'pulled', 'by', 'a', 'large', 'by', 'a', 'few', 'horses', '.', '<eos>']\n",
      "[Epoch 19 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'a', 'heavily', 'pulled', 'is', 'being', 'pulled', 'by', 'a', 'large', 'bull', '.', 'horses', '.', '<eos>']\n",
      "[Epoch 20 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'a', 'heavily', 'pulled', 'thrown', 'by', 'a', 'large', 'bull', 'of', 'horses', '.', '<eos>']\n",
      "[Epoch 21 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'several', 'men', 'being', 'pulled', 'by', 'a', 'large', ',', 'a', 'large', 'group', 'of', 'horses', '.', '<eos>']\n",
      "[Epoch 22 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'many', 'men', 'being', 'pulled', 'by', 'a', 'large', 'river', 'by', 'horses', '.', '<eos>']\n",
      "[Epoch 23 / 100]\n",
      "Translated example sentence: \n",
      " ['<sos>', 'a', 'boat', 'with', 'a', 'men', 'being', 'pulled', 'by', 'a', 'large', 'river', 'of', 'horses', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
    "# a boat with several men on it is pulled ashore by a large team of horses.\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, german, english, device, max_length=50\n",
    "    )\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        inp_data = batch.src.T.to(device)\n",
    "        target = batch.trg.T.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        output = output[:, 1:].reshape(-1, output.shape[2])\n",
    "        target = target[:, 1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhlVEFMfOQLN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sequence2sequence.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
