{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "developed-dayton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "type(random.uniform(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "proud-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "a = random.uniform(-1, 1)\n",
    "b = random.uniform(-1, 1)\n",
    "w = np.array([a, b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "relative-poker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08261434,  0.69080893])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "herbal-pressing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sound-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13150651809049374"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "theoretical-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clear-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noticed-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import heapq\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fresh-marijuana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 581888\n"
     ]
    }
   ],
   "source": [
    "path = '1661-0.txt'\n",
    "text = open(path, encoding='utf-8').read().lower()\n",
    "# text is string datatype\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "virtual-amplifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeff\\nproject gutenberg's the adventures of sherlock holmes, by arthur conan doyle\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, gi\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "piano-lyric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project', 'gutenberg', 's', 'the', 'adventures']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "words = tokenizer.tokenize(text)\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "rolled-minutes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8201"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = np.unique(words)\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
    "# unique_word_index = {c: i for i, c in enumerate(unique_words)}\n",
    "len(unique_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "speaking-flexibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '000', '1', '10', '100'], dtype='<U18')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "monetary-senegal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gutenberg', 's', 'the', 'adventures', 'of']\n",
      "sherlock\n"
     ]
    }
   ],
   "source": [
    "WORD_LENGTH = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(len(words)-WORD_LENGTH):\n",
    "    prev_words.append(words[i: i+WORD_LENGTH])\n",
    "    next_words.append(words[i+WORD_LENGTH])\n",
    "print(prev_words[1])\n",
    "print(next_words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fifteen-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
    "y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
    "for i, each_words in enumerate(prev_words):\n",
    "    for j, each_word in enumerate(each_words):\n",
    "        X[i, j, unique_word_index[each_word]] = 1\n",
    "    y[i, unique_word_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interim-watershed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109221, 5, 8201)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "equal-bobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109221, 8201)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conditional-stable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8201"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "least-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
    "model.add(Dense(len(unique_words), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exposed-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "811/811 [==============================] - 79s 83ms/step - loss: 6.3658 - accuracy: 0.0827 - val_loss: 7.0421 - val_accuracy: 0.1018\n",
      "Epoch 2/2\n",
      "811/811 [==============================] - 59s 72ms/step - loss: 5.6386 - accuracy: 0.1458 - val_loss: 7.8937 - val_accuracy: 0.1064\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "# since output is one_hot encoded we use c_c as loss and it also 2D array\n",
    "# if output is 1D array we use s_c_c\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "varied-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               4264960   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8201)              1057929   \n",
      "=================================================================\n",
      "Total params: 5,322,889\n",
      "Trainable params: 5,322,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "detailed-tuning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049728"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*8201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "simple-pulse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057929"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1049728+8201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sophisticated-immune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [6.009746551513672, 5.767683982849121],\n",
       " 'accuracy': [0.10848215222358704, 0.1473703533411026],\n",
       " 'val_loss': [7.042056083679199, 7.893716812133789],\n",
       " 'val_accuracy': [0.10179421305656433, 0.10637129098176956]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "trying-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "nominated-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_words(text, n):\n",
    "    X_test = prepare_input(text)\n",
    "    y_pred = model.predict(X_test, verbose=0)[0]\n",
    "    top_n_indices = heapq.nlargest(n, range(len(y_pred)), y_pred.take) # gives top 3 indices of max values\n",
    "    return unique_words[top_n_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "engaged-characterization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'of', 'in', 'to', 'a'], dtype='<U18')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_words(\"It is not a lack\".lower(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "irish-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    \"It is not a lack of love, but a lack of friendship that makes unhappy marriages.\",\n",
    "    \"That which does not kill us makes us stronger.\",\n",
    "    \"I'm not upset that you lied to me, I'm upset that from now on I can't believe you.\",\n",
    "    \"And those who were seen dancing were thought to be insane by those who could not hear the music.\",\n",
    "    \"It is hard enough to remember my opinions, without also remembering my reasons for them!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "reported-ontario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is not a lack\n",
      "\n",
      "That which does not kill\n",
      "\n",
      "I'm not upset that you\n",
      "\n",
      "And those who were seen\n",
      "\n",
      "It is hard enough to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in quotes:\n",
    "    l = q.split()[:5]\n",
    "    s = ' '\n",
    "    text = s.join(l)\n",
    "    print(text) \n",
    "    # print(predict_words(text, 5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-construction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
